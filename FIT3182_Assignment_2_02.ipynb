{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28accc5",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\"> FIT3182: Big Data Management and Processing (2025) </span>\n",
    "---\n",
    "\n",
    "Teaching Team:\n",
    "\n",
    "Faculty of Information Technology, Monash University, Australia\n",
    "* A/Prof. David Taniar (Chief Examiner) | david.taniar@monash.edu\n",
    "\n",
    "School of Information Technology, Monash University, Malaysia\n",
    "* Vishnu Monn (Unit Coordinator) | vishnu.monn@monash.edu\n",
    "* Shageenderan Sapai | shageenderan.sapai@monash.edu\n",
    "* Henry Quan Bi Pay | quan.pay@monash.edu\n",
    "* Ruturaj Reddy | ruturaj.reddy@monash.edu\n",
    "* Chai Wai Jin (Class Assistant) | wcha0106@student.monash.edu\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af82432",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  Group Information</span>\n",
    "---\n",
    "Note: Group members need to be enrolled in the same tutorial day and time slot.\n",
    "\n",
    "Your tutorial day and time: **[Enter your tutorial day and time here ]**    <br/>\n",
    "\n",
    "1st group member\n",
    "\n",
    "Surname: **[Enter your surname here]**  <br/>\n",
    "Firstname: **[Enter your firstname here ]**    <br/>\n",
    "Student ID: **[Enter your ID here ]**    <br/>\n",
    "Email: **[Enter your email  here ]**    <br/>\n",
    "\n",
    "2nd group member\n",
    "\n",
    "Surname: **[Enter your surname here]**  <br/>\n",
    "Firstname: **[Enter your firstname here ]**    <br/>\n",
    "Student ID: **[Enter your ID here ]**    <br/>\n",
    "Email: **[Enter your email  here ]**    <br/>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10027af0",
   "metadata": {},
   "source": [
    "# Streaming Application\n",
    "### Due: <span style=\"color:red\">11:55pm MYT, 27th May 2025</span>  (Tuesday)\n",
    "\n",
    "#### <span style=\"color:red\">Important note:</span> This is an **group** assignment with two students (max) per group. You or your group partner can share the code and outcomes of this assignment. However, you should not attempt to post questions on EdForum or any other online platform seeking solutions to the answers. If you require clarification on the assignment questions, you can post a post on EdForum or seek consultation from the tutors. In addition, AI and generative tools may be used in Guided ways.  However, students will be required to demonstrate a comprehensive understanding of the submitted work, failing which significant marks will be deducted from the submitted work. Even though this is a group work, each student is required to submit the assignment work in Moodle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb43d2",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "This notebook has been prepared for you to complete Assignment 2. The theme of this assignment is about practical knowledge and skills in streaming application using Spark and Kafka. **The total marks for this notebook is 30 marks, which is equivalent to 30 percentage points of the total coursework marks for this unit.**\n",
    "\n",
    "* Before getting started, you should read the entire notebook carefully once to understand what you need to do.\n",
    "\n",
    "* Always use the data from the provided `.csv` files to answer the questions unless stated otherwise.\n",
    "\n",
    "This assignment contain **3 parts**:\n",
    "\n",
    "* **Part 1**: MongoDB Data Model (5 Marks)\n",
    "* **Part 2**: Streaming Application (20 Marks)\n",
    "* **Part 3**: Documentation and comments to describe the proposed solution in the submitted notebook (5 Marks)\n",
    "* **Part 4**: Code demo and interview (Negative marking)\n",
    "\n",
    "Required Software:\n",
    "\n",
    "* You will be using Python 3. Answer all questions inside this Jupyter Notebook\n",
    "* Please use the provided Docker to load the Jupyter Notebook\n",
    "\n",
    "**Hint**: This assignment was essentially designed based on the seminars and applied sessions covered from Week 6 to Week 11. You are strongly encouraged to go through these contents thoroughly which might help you to complete the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d6830c",
   "metadata": {},
   "source": [
    "### Assignment Marking\n",
    "\n",
    "The marking of this assignment is based on quality of work you have submitted rather than just quantity. Marking starts from 0 and goes up based on tasks you have successfully completed and their quality, for example, how well the code submitted follows programming standards, code documentation, presentation of the assignment, readability of the code, organization of the code and so on. Please find the PEP 8 -- Style Guide for Python Code [here](https://www.python.org/dev/peps/pep-0008/) for your reference. Please refer to marking guidelines in Moodle for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652a7b4",
   "metadata": {},
   "source": [
    "### What to Submit\n",
    "\n",
    "This assignment is to be completed individually and submitted to Moodle unit site. By the due date, you are required to submit the following files to the corresponding Assignment (Dropbox) in Moodle.\n",
    "\n",
    "* **xxx_assignment02_data_design_streaming.ipynb**: this is your main Python notebook solution source file (the data design and streaming application).\n",
    "* **xxx_assignment02_producer_a/b/c.ipynb**: this is your Python notebook solution to run the Kafka producer that reads from one of the camera event files. If you are running multiple producers concurrently in the main notebook, then this file is optional.\n",
    "* **xxx_assignment02_visualisation.ipynb**: this is your Python notebook solution containing the data visualisation.\n",
    "* **xxx_assignment02_code.zip** (if applicable): this is a zip file that contains python files with custom-defined classes and functions to be used in notebook.\n",
    "\n",
    "where `xxx` represents the student ID of each group member. For example, if your student ID is <span style=\"color:red\">12345</span> and your group partner's ID is is <span style=\"color:red\">54321</span>, then your submission file name would be <span style=\"color:red\">12345_54321_assignment02_data_design_streaming.ipynb</span>. Please do the same for all of the submission files.\n",
    "\n",
    "Your assignment will be assessed based on the content of the submitted files in Moodle. We will use the same docker image as provided in this unit when marking your assignment. **If you used additional libraries, please include pip commands in your Jupyter notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f836d",
   "metadata": {},
   "source": [
    "### Plagiarism and Collusion\n",
    "\n",
    "Plagiarism and collusion are serious academic offenses at Monash University. Students must not share their work with any student. Students should consult policy linked [here](https://www.monash.edu/students/academic/policies/academic-integrity) for more information. See also the video linked on the Moodle page under the Assignment block.\n",
    "\n",
    "The submitted notebook files will be checked for collusion or plagiarism. Students suspected of colluding or plagiarising the assignment will be reported to the Student Conduct and Complaints Department for academic misconduct. Consequently, your grade for this unit will be withheld until the investigation is complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99713db4",
   "metadata": {},
   "source": [
    "### Generative AI usage\n",
    "\n",
    "AI & Generative AI tools may be used in GUIDED ways within this assessment / task as per the guidelines provided.\n",
    " \n",
    "In this task, AI can be used as specified for one or more parts of the assessment task as per the instructions.\n",
    "You may use AI to help you learn how to solve the assignment.\n",
    "\n",
    "Where used, AI must be used responsibly, clearly documented and appropriately acknowledged (see [Learn HQ](https://www.monash.edu/student-academic-success/build-digital-capabilities/create-online/acknowledging-the-use-of-generative-artificial-intelligence)).\n",
    " \n",
    "Any work submitted for a mark must:\n",
    "represent a sincere demonstration of your human efforts, skills and subject knowledge that you will be accountable for.\n",
    "adhere to the guidelines for AI use set for the assessment task.\n",
    "reflect the University’s commitment to academic integrity and ethical behaviour.\n",
    "Inappropriate AI use and/or AI use without acknowledgement will be considered a breach of academic integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6496b475",
   "metadata": {},
   "source": [
    "### Late submissions \n",
    "Extensions and other individual alterations to the assessment regime will only be considered using the University’s [Special Consideration Policy](https://www.monash.edu/students/admin/exams/changes/special-consideration). There is a 10% penalty per day, including weekends, for late submission. Please note that short extensions are not allowed for group submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe384a47",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Preliminary</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbe6061",
   "metadata": {},
   "source": [
    "### Scenario Background\n",
    "\n",
    "Malaysia’s road network consistently ranks among the busiest and most accident‑prone in Southeast Asia. Federal roads alone account for a significant proportion of traffic incidents, particularly during peak travel periods and festive seasons, when speed limits of up to 90 km/h (and 110 km/h on expressways) are frequently exceeded in an effort to cover long distances quickly. Since 2012, the Automated Enforcement System (AES) has deployed static speed‑light and red‑light cameras at fixed points to deter speeding and dangerous cornering. However, these point‑capture devices suffer from well‑documented loopholes: drivers can simply decelerate when approaching a camera and then accelerate immediately afterward, rendering enforcement uneven and often ineffective.\n",
    "\n",
    "To address these shortcomings, the Malaysian Government has begun rolling out the Automated Awareness Safety System (AWAS), a point‑to‑point average‑speed enforcement mechanism (Jamil et al., 2022). Figure 1 illustrates an overview of the AWAS system. AWAS leverages pairs of Ekin Spotter modular cameras equipped with 360° video surveillance and Automatic Number Plate Recognition (ANPR) to record each vehicle’s passage at two distinct checkpoints along a highway segment. By logging the exact timestamps at “Point A” and “Point B,” the system computes the travel time over a known distance (typically 1–5 km) and derives the average speed. Any average exceeding the legal limit (e.g., 110 km/h on expressways) automatically triggers a violation notice, regardless of momentary decelerations.\n",
    "\n",
    "While AWAS promises more consistent enforcement, it also introduces significant data‑processing challenges. Each camera pair generates a continuous stream of high‑volume events—potentially thousands per minute during peak hours—that must be matched by license plate, ordered by event time, and joined across streams to compute speeds in near real time. The system must tolerate out‑of‑order or late‑arriving events (e.g., network delays), bound state growth via watermarks, and guarantee end‑to‑end exactly‑once processing to prevent duplicate violation records. These requirements make AWAS an ideal case study for a streaming Big Data architecture using Apache Kafka for ingestion, Apache Spark Structured Streaming for stateful stream–stream joins, and MongoDB for scalable storage of both raw events and flagged violations.\n",
    "\n",
    "Reference:\n",
    "\n",
    "Jamil, H. M., Shabadin, A., & Ibrahim, M. K. A. (2022). Automated Awareness Safety System (AwAS) for Red Light Running in Malaysia: An Analysis of Four-year Data on Its Effectiveness. Journal of the Society of Automotive Engineers Malaysia, 6(1), 19-29."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc8e2b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "    <img src=\"FIT3182_A2_Fig_1.png\"></img>\n",
    "    <p style=\"text-align: center\">Figure 1 - Overview of AWAS</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9965391",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this assignment, you are provided the following `.csv` files to help you simulate the AWAS streaming application. The following details the information about the dataset.\n",
    "\n",
    "#### vehicle.csv\n",
    "* car_plate (a string-based unique identifier to each vehicle)\n",
    "* owner_name (a string that contains name of the owner)\n",
    "* owner_addr (a string that contains the address of the owner)\n",
    "* vechicle_type (a string that represents the vechile model)\n",
    "* registration_date (date and time when the vehicle was registered)\n",
    "\n",
    "#### camera.csv\n",
    "* camera_id (an integer-based unique identifier to camera location)\n",
    "* latitude (a float value representing latitude of camera)\n",
    "* longitude (a float value representing longitude of camera)\n",
    "* position (a float value tells at which kilometer point is the camera)\n",
    "* speed_limit (a float value of maximum legal speed for the segment)\n",
    "\n",
    "#### camera_event.csv\n",
    "* event_id (a string-based unique identifier to camera reading)\n",
    "* batch_id (a integer-based identifier to batch reading)\n",
    "* car_plate (a string-based unique identifier to each vehicle)\n",
    "* camera_id (an integer-based unique identifier to camera location)\n",
    "* timestamp (a string that tells the timestamp when the vehicle passed the camera)\n",
    "* speed_reading (a float value that tells the instantaneous speed, recorded in km/h, by that camera)\n",
    "\n",
    "#### camera_event_historic.csv\n",
    "* violation_id (a string-based unique identifier for violation record)\n",
    "* car_plate (a string-based unique identifier to each vehicle)\n",
    "* camera_id_start (an integer-based unique identifier to starting camera location)\n",
    "* camera_id_end (an integer-based unique identifier to ending camera location)\n",
    "* timestamp_start (a string that tells the timestamp when the vehicle passed the starting camera)\n",
    "* timestamp_end (a string that tells the timestamp when the vehicle passed the ending camera)\n",
    "* speed_reading (a float value that tells the average speed, recorded in km/h, within the camera segment)\n",
    "\n",
    "<span style=\"color:red\">Important note:</span> Multiple files of camera_event.csv will be provided, each corresponds to a camera respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a9aab",
   "metadata": {},
   "source": [
    "### Required Imports\n",
    "\n",
    "Import necessary Python modules in the cell below. Include `pip` statement if external libraries/modules are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce3d069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (3.6.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: folium in /opt/conda/lib/python3.8/site-packages (0.18.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from folium) (2.28.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from folium) (1.23.5)\n",
      "Requirement already satisfied: xyzservices in /opt/conda/lib/python3.8/site-packages (from folium) (2022.9.0)\n",
      "Requirement already satisfied: branca>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from folium) (0.8.1)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/conda/lib/python3.8/site-packages (from folium) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2>=2.9->folium) (2.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->folium) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->folium) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->folium) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->folium) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "# Add pip statement if necessary\n",
    "!pip install matplotlib\n",
    "!pip install folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b0dee",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 1: MongoDB Data Model</span>\n",
    "\n",
    "This section consists of 3 sub-questions\n",
    "\n",
    "In this task, you will study the data model of a streaming application. You will demonstrate the theoretical knowledge by designing appropriate data model based on the provided dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a97125d",
   "metadata": {},
   "source": [
    "### Task 1.1 Collection Design\n",
    "\n",
    "In this task, design **at least** the following 3 collections. Add other collections if they are necessary.\n",
    "* Vehicle (Store static metadata about each vehicle)\n",
    "* Camera (Store static definitions of each camera)\n",
    "* Violation (Records of flagged violations)\n",
    "\n",
    "For each collection, provide\n",
    "* 1-2 sentence description of why this collection exists\n",
    "* document schema and a sample document\n",
    "* indexes (if any) by specifying\n",
    "    * Fields (and sort order if applicable)\n",
    "    * Type\n",
    "    * Purpose of the index\n",
    "* shard key strategy (if any) by specifying\n",
    "    * Chosen shard key\n",
    "    * Shard key type\n",
    "    * Rationale\n",
    "* data retention policy (if applicable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c709fe8c",
   "metadata": {},
   "source": [
    "**Vehicle Collection**\n",
    "* description : This collection exists to store information about vehicles, which are referenced by the Violation collection using the car plate number. Since camera events only store the car plate number, this collection is needed to retrieve additional details about the vehicle recorded in a violation.\n",
    "* vehicle schema : \n",
    "    ```\n",
    "    {  \n",
    "  \"_id\": ObjectId,   \n",
    "  \"car_plate\": String,  \n",
    "  \"owner_name\": String,  \n",
    "  \"owner_addr\" : String,  \n",
    "  \"vehicle_type\": String,  \n",
    "  \"registration_date\": String,  \n",
    "}\n",
    "    ```\n",
    "* sample document :\n",
    "```\n",
    "{  \n",
    "  \"_id\": ObjectId(\"68384ab09283050abd473ecf\"),   \n",
    "  \"car_plate\": \"FT 02\",  \n",
    "  \"owner_name\": \"Goh Mei Wei\",  \n",
    "  \"owner_addr\" : \"943 Jalan Bukit Mawar, Kuala Lumpur\",  \n",
    "  \"vehicle_type\": \"Coupe\",  \n",
    "  \"registration_date\":Date(2006-08-22T03:18:00),  \n",
    "}\n",
    "``` \n",
    "* indexes :\n",
    "    * Field : **car_plate**\n",
    "    * Type : single field\n",
    "    * justification : Since most queries on the vehicle collection use the car_plate field—especially when joining with violations that reference vehicles by car plate—indexing car_plate significantly improves lookup performance.\n",
    "    \n",
    "    \n",
    "* shared key strategy :\n",
    "    * chosen shared key : **car_plate**\n",
    "    * type : **hashed**\n",
    "    * justification : Given the large volume of vehicle data, a shard key strategy is implemented for the vehicle collection. \"car_plate\" is use as the shard key because its values are approximately uniformly distributed, which ensures balanced data distribution across shards and improves query efficiency, since searches are frequently filtered by license plate\n",
    "* data retention policy : Vehicle data does not have an expiration date, as it is expected to be stored permanently unless a vehicle is explicitly unregistered or archived.\n",
    "\n",
    "**camera Collection**\n",
    "* description : This collection stores static metadata about each camera’s physical location and operational parameters. \n",
    "* vehicle schema : \n",
    "    ```\n",
    "    {\n",
    "  \"_id\" : ObjectId,\n",
    "  \"camera_id\" : Number,\n",
    "  \"latitude\" : Number,\n",
    "  \"longitude\" : Number,\n",
    "  \"position\" : Number,\n",
    "  \"speed_limit\" : Number\n",
    "}\n",
    "    ```\n",
    "    \n",
    "* sample document :\n",
    "```\n",
    "{\n",
    "  \"_id\" : ObjectId(\"68362fae02ea8ad939fe15c0\"),\n",
    "  \"camera_id\" : 2,\n",
    "  \"latitude\" : 2.162418757,\n",
    "  \"longitude\" : 102.6524549,\n",
    "  \"position\" : 153.5,\n",
    "  \"speed_limit\" : 110\n",
    "}\n",
    "``` \n",
    "\n",
    "* indexes : No indexes are created for this collection as it is expected to remain relatively small.\n",
    "\n",
    "* shared key strategy : No sharding is applied because the collection size is small and does not justify sharding overhead.\n",
    "\n",
    "* data retention policy :  data is retained indefinitely unless manual updates or deletions occur.\n",
    "\n",
    "**violations Collection**\n",
    "* description : This collection stores traffic violations identified from camera events. A violation is recorded if a vehicle’s speed, either instantaneous (from a single camera) or average (between two cameras), exceeds the speed limit. For instantaneous violations, camera_id_start and camera_id_end are the same. Each violation references the car_plate from the Vehicle collection to link to vehicle details.\n",
    "* vehicle schema : \n",
    "    ```\n",
    "    {  \n",
    "  \"_id\": ObjectId,   \n",
    "  \"violation_id\": String,  \n",
    "  \"car_plate\": String,  \n",
    "  \"camera_id_start\" : Number,  \n",
    "  \"camera_id_end\": Number,  \n",
    "  \"timestmap_start\": String,\n",
    "  \"timestamp_end\" : String,\n",
    "  \"speed_reading\" : Number,\n",
    "  \"type\" : String \n",
    "}\n",
    "    ```\n",
    "    \n",
    "* sample document :\n",
    "```\n",
    "    {  \n",
    "  \"_id\": ObjectId(\"68381d7fe6bb257c8ef0c443\"),   \n",
    "  \"violation_id\": \"0ff38c74-7ee6-41cd-bc26-3a6060604a02\",  \n",
    "  \"car_plate\": \"YE 6517\",  \n",
    "  \"camera_id_start\" : 1,  \n",
    "  \"camera_id_end\": 1,  \n",
    "  \"timestmap_start\": \"2018-11-14T08:30:11\",\n",
    "  \"timestamp_end\" : \"2018-11-14T08:30:35.821118\",\n",
    "  \"speed_reading\" : 123.10,\n",
    "  \"type\" : \"average\"\n",
    "}\n",
    "``` \n",
    "\n",
    "* indexes :\n",
    "    * Field : **violation_id**\n",
    "    * Type : single field\n",
    "    * purpose of the index : When inserting a new violation in the pipeline, violation_id is use for the query filter, indexing violation_id will greatly improve performance. Since this operation happens often, the index avoids expensive collection scans and makes the ReplaceOne() operation faster and more efficient.\n",
    "    * Field : **car_plate**\n",
    "    * Type : single field\n",
    "    * purpose of the index : enable fast lookup for car_plate filter query , which is likely to be common.\n",
    "\n",
    "* shared key strategy :\n",
    "    * chosen shared key : **violation_id**\n",
    "    * type : **hashed**\n",
    "    * justification : Similar to the Vehicle collection, the high volume of data in the Violation collection justifies the use of a shard key strategy. The **violation_id** field is chosen as the shard key for the same reasons, as it approximately uniformly random\n",
    "    \n",
    "    \n",
    "**no_match_record Collection**\n",
    "* description : This collection stores camera events that failed to find a matching event from another camera within a specified time frame. Future incoming camera events are matched against this collection to identify possible delayed matches.\n",
    "* vehicle schema : \n",
    "    ```\n",
    "    {  \n",
    "  \"_id\": ObjectId,   \n",
    "  \"event_id\": String,  \n",
    "  \"car_plate\": String,  \n",
    "  \"camera_id\" : Number,  \n",
    "  \"timestmap\": String,\n",
    "  \"speed_reading\" : Number\n",
    "  \"position\" : Number,\n",
    "  \"event_time\" : Date,\n",
    "  \"speed_limit\" : Number\n",
    "}\n",
    "    ```\n",
    "    \n",
    "* sample document :\n",
    "```\n",
    "    {  \n",
    "  \"_id\": ObjectId(\"683632d971275163644c731e\"),   \n",
    "  \"event_id\": '7c500f87-f94c-48a2-9389-cd50a5486d05',  \n",
    "  \"car_plate\": 'XY 7365',  \n",
    "  \"camera_id\" : 2,  \n",
    "  \"timestmap\": '2024-01-01T08:43:01.555121',\n",
    "  \"speed_reading\" : 166.2,\n",
    "  \"position\" : 153.5,,\n",
    "  \"event_time\" : ISODate(\"2024-01-01T08:43:01.555Z\"),\n",
    "  \"speed_limit\" : 110\n",
    "}\n",
    "``` \n",
    "\n",
    "* indexes : No indexes are created for this collection as it is expected to remain relatively small.\n",
    "\n",
    "* shared key strategy : No sharding is applied because the collection size is small and does not justify sharding overhead.\n",
    "\n",
    "* data retention policy : Records in this collection are retained for one day. Any unmatched event older than one day is considered stale and removed to keep the data relevant and manageable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9db5c3",
   "metadata": {},
   "source": [
    "### Task 1.2 Collection Relationship\n",
    "\n",
    "In this task, specify the relationships between collections and explain whether you choose to embed data or store references. Justify your choice in terms of:\n",
    "* Read/write patterns\n",
    "* Data duplication versus Join cost\n",
    "* Consistency requirements (if applicable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3262b",
   "metadata": {},
   "source": [
    "Collection relationship :  \n",
    "The **violation** collection references the _car_plate_ field from the **vehicle** collection. Since accessing vehicle information for a given violation is typically done in offline analysis rather than in real-time, there's no strong performance requirement that justifies embedding the entire vehicle document into each violation record. Furthermore, the vehicle collection is indexed on _car_plate_, so lookups or joins between violation and vehicle based on this field can still be performed efficiently when needed.\n",
    "\n",
    "The **no_match_record** collection references the _car_plate_ field from the **vehicle** collection and embeds information from the **camera** collection about the camera where the event was recorded. Since full vehicle details are not required for violation detection, embedding them would introduce unnecessary overhead. In contrast, embedding camera data is enables efficient computation of average speed when future events are matched with these records. Although this introduces some duplication, the memory impact is minimal because unmatched records are purged after one day, keeping the collection size manageable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797ff17",
   "metadata": {},
   "source": [
    "### Task 1.3 Discussion\n",
    "\n",
    "In this task, discuss whether your model supports\n",
    "* Consistency and Idempotency\n",
    "    * Does it support idempotent writes?\n",
    "    * Explain any upsert pattern in `violation` collection\n",
    "* Scalability and Fault-Tolerance\n",
    "    * Can your data model support high ingest rates?\n",
    "    * Can your data model support low-latency lookups?\n",
    "\n",
    "Justify and explain the trade-off made in your design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e2e8e",
   "metadata": {},
   "source": [
    "The violation collection supports idempotent writes because each record is inserted using ReplaceOne with upsert=True, keyed by a unique violation_id \n",
    "```\n",
    "ReplaceOne({\"violation_id\": violation_id}, record, upsert=True)\n",
    "```\n",
    "where violation_id is constructed from the camera event_id that captured the violation. This ensures that each violation corresponds to a single, unique document. If the violation record with the specified violation_id exists already in the collection, it try to update it, if not, a new violation record is inserted.\n",
    "As a result, retrying the same write operation will not introduce duplicates or side effect, since the operation always results in the same final state for the given violation_id.\n",
    "\n",
    "\n",
    "The violation records are written using bulk operations, which improves the efficiency of ingesting large volumes of data and supports high write throughput. The use of a simple retry mechanism combined with idempotent ReplaceOne operations ensures fault tolerance, as retrying writes due to system failures will not lead to duplicated or inconsistent records. \n",
    "\n",
    "Low-latency lookups are supported through an index on the car_plate field, allowing efficient querying of violation records by vehicle. Although indexing car_plate adds some memory and storage overhead, especially since the violation_id is already indexed for violations collection, this is a reasonable trade-off given that such queries are likely to be frequent. While ReplaceOne with upsert=True does introduce more overhead compared to insert_one, it provides robustness by preventing duplicate entries and ensuring consistency. In the context of speed violation detection, where data integrity and reliability are critical, this added cost is justified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eafe9a9",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 2: Streaming Application</span>\n",
    "\n",
    "This section consists of 2 sub-questions. \n",
    "\n",
    "In this task, you will implement a streaming application to simulate the AWAS system. Figure 2 illustrates an overview of the streaming architecture that is to be developed to simulate AWAS. Implementation is expected to be following programming standards with high readability (supported with documentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51a153",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\"> \n",
    "    <img src=\"FIT3182_A2_Fig_2.png\"></img>\n",
    "    <p style=\"text-align: center\">Figure 2 - Overview of streaming application to simulate AWAS </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474fc3a8",
   "metadata": {},
   "source": [
    "### Task 2.1 Data Stream Processing\n",
    "\n",
    "In this task, you will implement multiple **Apache Kafka** producers to simulate the real-time streaming of the data, which will be processed by **Apache Spark Structured Streaming** client and then inserted into MongoDB.\n",
    "\n",
    "*<span style=\"color:red\">Important note:</span> You are expected to use the same data model from Task 1. To make the streaming data consistent for the model, you may need to make some changes to the streaming data before building the model or inserting it to MongoDB.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a989065f",
   "metadata": {},
   "source": [
    "#### Event Producer\n",
    "\n",
    "**Event Producer A**: Write a python program that loads all the data from `camera_event_A.csv` and feed the data to the stream in batches every $n$ seconds. You can refer to the batch id column in the csv file to identify the data to read and send to the stream. The typical value for $n$ is 5 seconds. You might need to append additional information such as producer information to identify the producer. If you are running this producer in a separate Jupyter notebook file, save the file as **xxx_assignment02_producer_a.ipynb**, where **xxx** represents the student IDs of the group members.\n",
    "\n",
    "**Event Producer B**: Write a python program that loads all the data from `camera_event_B.csv` and feed the data to the stream in batches every $n$ seconds. You can refer to the batch id column in the csv file to identify the data to read and send to the stream. The typical value for $n$ is 5 seconds. You might need to append additional information such as producer information to identify the producer. If you are running this producer in a separate Jupyter notebook file, save the file as **xxx_assignment02_producer_b.ipynb**, where **xxx** represents the student IDs of the group members.\n",
    "\n",
    "**Event Producer C**: Write a python program that loads all the data from `camera_event_C.csv` and feed the data to the stream in batches every $n$ seconds. You can refer to the batch id column in the csv file to identify the data to read and send to the stream. The typical value for $n$ is 5 seconds. You might need to append additional information such as producer information to identify the producer. If you are running this producer in a separate Jupyter notebook file, save the file as **xxx_assignment02_producer_c.ipynb**, where **xxx** represents the student IDs of the group members."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c7a85d",
   "metadata": {},
   "source": [
    "#### Streaming Application\n",
    "\n",
    "Write a streaming application using Apache Spark Structured Streaming API which processes data in batches. Each batch should contain 0 or more camera event (from event producer). The streaming application should process the data as follows.\n",
    "* Join the streaming data from the producers and determine if a vehicle should be flagged as violation. You should drop any data pair if the timestamp and the order of the camera does not match.\n",
    "* If there is a violation detected, store it into MongoDB straight away.\n",
    "* If there is no violation detected, drop the record.\n",
    "* Due to the dynamic nature of moving vehicle, the time of vehicle completing the camera segment may vary and you should decide how many records and how long the records should be stored in the buffer until a pair is identified.\n",
    "\n",
    "##### Violation Detection Rule\n",
    "A vehicle is flagged as violating the speed limit if any one of the following happens.\n",
    "* Instantaneous speed of vehicle exceed the speed limit of the recording camera\n",
    "* Average speed of vehicle exceed the speed limit of the ending camera\n",
    "\n",
    "<span style=\"color:red\">Important Note:</span> *Only one record for a car per day is recorded in the database. If the car violates at **different cameras**, the record should be merged together into a single record to be stored in the database.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d11c4a",
   "metadata": {},
   "source": [
    "### Task 2.2 Data Visualisation\n",
    "\n",
    "In this task, you will implement a program to visualize the joined streaming data. For the incoming camera event(s), \n",
    "* plot the number of violation against arrival time. You need to label some interesting points such as maximum and minimum values. \n",
    "* In addition to that, plot the speed against arrival time. You need to include some interesting points such as average and maximum values.\n",
    "\n",
    "For visualization on the data stored in the database, you have to plot a map using camera location. On the map, annotate\n",
    "* number of violations between the checkpoints\n",
    "* identify hotspot (e.g. when number of violations exceed certain threshold within a time in a day)\n",
    "\n",
    "Explain and justify the plots and the inclusion of the interesting points. Set your own threshold for the hotspot.\n",
    "\n",
    "If you are running this task in a separate Jupyter notebook file, save the file as **xxx_assignment02_visualisation.ipynb**, where **xxx** represents the student IDs of the group members."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748b82f",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 3: Documentation and comments to describe the proposed solution in the submitted notebook</span>\n",
    "\n",
    "You should include sufficient comments and explanation Tasks 1 and 2 to describe your algorithm and/or code implementation. Please add additional markdown cells to explain your work. Adding extra illustrations to describe your method will also add to the marks in this part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f29b622",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 4: Code demo and interview</span>\n",
    "\n",
    "In this task, you will present and showcase the simulation. After the assignment due date, you will be asked to attend an interview/demo session to showcase your application. Your interviewer will ask you a few questions in relation to your application and assess your understanding.\n",
    "\n",
    "During the code demo, your work will be evaluated and assessed based on the marking guideline. Group members will obtain the same marks based on the code demo, unless there is an imbalance in contributions between students in a team. Additionally, each team member will be interviewed to explain the submitted work. The interview represents an individual assessment and a score between 0 and 1 will be awarded, which is then multipled with the marks obtained during the code demo.\n",
    "\n",
    "Interviews for Assignment-2 will be conducted during Week 12 lab sessions. If you are granted an extension from special consideration, the interview will be conducted during SWOT-VAC week."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
